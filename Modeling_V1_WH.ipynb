{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Modeling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stopwords_english = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load news articles\n",
    "Path = \"C:/Users/Winnie/Documents/2020 Spring/NLP/Final Project/Data/All_Candidates/\"\n",
    "Biden = pd.read_csv(Path + 'Joe_Biden.csv')\n",
    "Sanders = pd.read_csv(Path + 'Bernie_Sanders.csv')\n",
    "Trump = pd.read_csv(Path + 'Donald_Trump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select text and news company names\n",
    "Biden_news = Biden[['text', 'media']]\n",
    "Sanders_news = Sanders[['text', 'media']]\n",
    "Trump_news = Trump[['text', 'media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide highlightingAbstractTranslateUndo Transla...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           media\n",
       "0  Hide highlightingFull TextTranslateUndo Transl...  New York Times\n",
       "1  Hide highlightingAbstractTranslateUndo Transla...  New York Times"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Biden_news.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create corpus for each news companies (NYT, TWP, and WSJ)\n",
    "\n",
    "def create_corpus(Biden_news, Sanders_news, Trump_news, media_name):\n",
    "    \n",
    "    df1 = Biden_news.loc[Biden_news['media'] == media_name]\n",
    "    df2 = Sanders_news.loc[Sanders_news['media'] == media_name]\n",
    "    df3 = Trump_news.loc[Trump_news['media'] == media_name]\n",
    "    frames = [df1, df2, df3]\n",
    "    df = pd.concat(frames, ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small corpus for each news company\n",
    "NYT = create_corpus(Biden_news, Sanders_news, Trump_news, media_name = 'New York Times')\n",
    "WSJ = create_corpus(Biden_news, Sanders_news, Trump_news, media_name = 'Wall Street Journal')\n",
    "TWP = create_corpus(Biden_news, Sanders_news, Trump_news, media_name = 'The Washington Post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide highlightingAbstractTranslateUndo Transla...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           media\n",
       "0  Hide highlightingFull TextTranslateUndo Transl...  New York Times\n",
       "1  Hide highlightingAbstractTranslateUndo Transla...  New York Times\n",
       "2  Hide highlightingFull TextTranslateUndo Transl...  New York Times\n",
       "3  Hide highlightingFull TextTranslateUndo Transl...  New York Times\n",
       "4  Hide highlightingFull TextTranslateUndo Transl...  New York Times"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create large corpus for all \n",
    "corpus_All_Medias = pd.concat([NYT, WSJ, TWP], axis = 0, ignore_index = True)\n",
    "corpus_All_Medias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hide highlightingAbstractTranslateUndo Translation FromToTranslateTranslation in progress... \\r\\n\\r\\n[[missing key: loadingAnimation]]The full text may take 40-120 seconds to translate; larger documents may take longer.\\r\\n\\r\\nCancel\\r\\nOverlayEndA new study, which found that Americans were reluctant to use the word â€œsheâ€� to describe a hypothetical president, highlights the sneaky ways language illuminates bias.You have requested \"on-the-fly\" machine translation of selected content from our databases. This functionality is provided solely for your convenience and is in no way intended to replace human translation. Show full disclaimerNeither ProQuest nor its licensors make any representations or warranties with respect to the translations. The translations are automatically generated \"AS IS\" and \"AS AVAILABLE\" and are not retained in our systems. PROQUEST AND ITS LICENSORS SPECIFICALLY DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES FOR AVAILABILITY, ACCURACY, TIMELINESS, COMPLETENESS, NON-INFRINGMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Your use of the translations is subject to all use restrictions contained in your Electronic Products License Agreement and by using the translation functionality you agree to forgo any and all claims against ProQuest or its licensors for your use of the translation functionality and any output derived there from. Hide full disclaimer\\r\\n\\r\\nLonger documents can take a while to translate. Rather than keep you waiting, we have only translated the first few paragraphs. Click the button below if you want to translate the rest of the document.\\r\\nTranslate AllFull TextTranslateUndo Translation FromToTranslateTranslation in progress... \\r\\n\\r\\n[[missing key: loadingAnimation]]The full text may take 40-120 seconds to translate; larger documents may take longer.\\r\\n\\r\\nCancel\\r\\nOverlayEndTurn on search term navigationTurn on search term navigation\\r\\n| Jump to first hitA new study, which found that Americans were reluctant to use the word â€œsheâ€� to describe a hypothetical president, highlights the sneaky ways language illuminates bias.\\r\\nIt was a blip of a moment during the Democratic debate last week, one perhaps overshadowed by a long discussion of the prospect of a female president. Responding to a question about climate change, Senator Elizabeth Warren of Massachusetts said, â€œI will do everything a president can do all by herself on the first day.â€�\\r\\nAll by herself. Did you clock the use of that word?\\r\\nA study released this month shows that you did â€” and that, in fact, it may have cost you a third of a second in reading time just now.\\r\\nHer. Itâ€™s a three-letter pronoun that, despite the seemingly endless debate over whether a woman can become president, feels relatively benign. But what if its use, or an unconscious aversion to its use, had some small power to influence voter perception? Could something as simple as a pronoun reflect, or even affect, the way voters understand power?\\r\\nThatâ€™s the question raised by the research, conducted by cognitive scientists and linguists at M.I.T., the University of Potsdam and the University of California, San Diego, who surveyed people during the run-up to the 2016 election. Wanting to understand how world events might influence language, the researchers hypothesized that the possibility a woman would be elected president at that time might override the implicit bias people had toward referring to the president as â€œhe.â€�\\r\\nBut what they found was that Americans â€” even young, self-identified Democratic women who believed Hillary Clinton would win â€” were reluctant to use â€œsheâ€� even in the context of a hypothetical president.\\r\\nâ€œThere seemed to be a real bias against referring to the next president as â€˜she,â€™â€� said Roger Levy, a professor of brain and cognitive sciences at M.I.T. and one of the authors of the study.\\r\\nWhen the researchers watched subjects in a reading setting â€” they were asked to read a short passage about the next president, pressing a button on a screen to reveal each word of the sentence â€” their bias was even more pronounced: The word â€œshe,â€� when referring to the future president, made people cognitively stumble, leading to a â€œconsiderable disruptionâ€� in reading time, said Titus von der Malsburg, another author of the study and a linguist at the University of Potsdam, in Germany.\\r\\nâ€œPeople had difficulties reading â€˜sheâ€™ even if the text had previously used â€˜she,â€™ showing how persistent and deeply ingrained this bias is,â€� he said.\\r\\nSo could struggling to say or read the word â€œsheâ€� in the context of a president affect our willingness to vote for a woman?\\r\\nâ€œThatâ€™s of course the million-dollar question,â€� said Dr. von der Malsburg.\\r\\nHe noted that if people gravitated toward male language when talking about presidents, that could indirectly contribute to a culture in which women were not seen as typical candidates.\\r\\nâ€œAnd that, in turn, would likely influence election outcomes because women would have to do extra work to convince voters that they can do the job,â€� he said.\\r\\nWhat lurks behind language?\\r\\nWhen it comes to women in politics â€” and specifically, women in the presidency â€” often lurking behind language are unconscious assumptions about women in power.\\r\\nâ€œWe are uneasy with the president as â€˜sheâ€™ because encountering it forces us to have in mind a new conception of â€˜president,â€™â€� the linguist Robin Lakoff said.\\r\\nDr. Lakoff, whose book â€œLanguage and Womanâ€™s Placeâ€� helped create the field of gender linguistics in the 1970s, said that language tended to reflect the beliefs of a particular moment in time.\\r\\nBut it can also shape them.\\r\\nResearch has found that the use of the pronoun â€œheâ€� can create a male bias in readers, that countries with gendered language have higher gender inequality and that even subtly sexist language may influence votersâ€™ likelihood of supporting a particular candidate.\\r\\nIn recent years, some governments and organizations have started paying more attention to the power of words, taking steps to update or replace gendered terms.\\r\\nIn 2013, Washington State joined Florida and Minnesota in combing through its state codes and statutes to adjust terms like â€œombudsmanâ€� (now â€œombudsâ€�) to be gender neutral. As Liz Watson, then senior counsel at the National Womenâ€™s Law Center, said at the time: â€œWords matter. Words help shape our perceptions about what opportunities are available to women and men.â€�\\r\\nAdministrators at Yale announced in 2017 that they would replace the words â€œfreshmanâ€� and â€œupperclassmanâ€� with â€œfirst-yearâ€� and â€œupper-levelâ€� students, joining several other universities that have informally made the change. And the singular â€œtheyâ€� â€” increasingly popular as both as substitute for â€œhe or sheâ€� and as a gender-neutral pronoun for those who identify as nonbinary â€” was recently declared the â€œWord of the Decadeâ€� by the American Dialect Society.\\r\\nThat would seem like progress, said the historian Barbara J. Berg. Yet when it comes to the halls of power, she said, the masculine â€œremains the default in our language.â€�\\r\\nIt is popular these days to tell the story of Abigail Adams, wife of the founding father John, who urged her husband in a letter in 1776 to â€œremember the ladies.â€� Lesser known is that his reply, in a letter back, called her request â€œsaucy.â€� (The word â€œshe,â€� of course, does not appear anywhere in the Declaration of Independence, nor does the word â€œwoman.â€�)\\r\\nAnd while, over the years, words like â€œmailman,â€� â€œpolicemanâ€� and â€œstewardessâ€� have been replaced with terms like â€œmail carrier,â€� â€œpolice officerâ€� and â€œflight attendant,â€� there are still plenty of phrases for which â€œheâ€� connotes power. Think â€œmanning the command post,â€� â€œmaestroâ€� or even â€œguyâ€� as a way to describe expertise. â€œAs in, â€˜Heâ€™s a stats guyâ€™ or â€˜Heâ€™s a policy guy,â€™â€� said Philip N. Cohen, a sociologist at the University of Maryland.\\r\\nThe 2018 midterm elections broke all sorts of records â€” and a historic number of women ran for office and won â€” and yet they also provided ample opportunity to hear (and see) the phrase â€œfreshman congresswoman.â€� Doesnâ€™t it sound sort of funny?\\r\\nDeborah Tannen, a linguist at Georgetown University, described how she had recently spoken with a group of female judges, some of whom recalled being referred to as â€œsirâ€� when on the bench. Presumably, Dr. Tannen said, the speakers were nervous â€” and â€œsirâ€� was an attempt to show respect.\\r\\nâ€œâ€˜Sirâ€™ is associated with respect to an extent that â€˜maâ€™amâ€™ is not,â€� Dr. Tannen said, noting that she, too, had occasionally stumbled over such words.\\r\\nOnce, she recalled, at an event in which Michelle Obama was speaking, a friend remarked that â€œDr. Bidenâ€� would also be in attendance.\\r\\nâ€œI thought to myself, â€˜Oh, I didnâ€™t know Joe Biden had a Ph.D.,â€™â€� she said. â€œAnd of course it was his wife, who I had met, and who I knew had a Ph.D. So even I do it, Dr. Tannen.â€�\\r\\nAnd then thereâ€™s â€œMadam.â€� During the 1970s, feminists fought for the adoption of a female equivalent of â€œMr.â€� â€” one that did not denote marital status â€” and were largely successful with the honorific â€œMs.â€� But male presidents in the United States are often addressed as â€œMr. President,â€� while a woman â€” if the way we refer to cabinet secretaries is any indication â€” would quite likely be â€œMadam President.â€�\\r\\nâ€œâ€˜Madamâ€™ could be a term of respect, but itâ€™s also the head of a brothel,â€� said Dr. Berg, the historian. â€œSo itâ€™s like this constant subtle reminder of a womanâ€™s status.â€�\\r\\nA candidate who can â€˜bring people with herâ€™\\r\\nBut a new breed of candidates may be flipping that script.\\r\\nDuring the recent Democratic debate, in addition to Ms. Warrenâ€™s use of â€œherselfâ€� in reference to the next president on more than one occasion, Senator Amy Klobuchar of Minnesota said in her closing statement, â€œWe need a candidate who is actually going to bring people with her.â€�\\r\\nSenator Kamala Harris of California, who dropped out of the race late last year, often did the same when she was running. As Californiaâ€™s first female attorney general, she sifted through the language that was written into the law â€” statutes referring to the attorney general as â€œheâ€� or â€œhisâ€� â€” and changed them.\\r\\nâ€œIâ€™ve always been very aware that when it comes to women holding leadership roles, we are sometimes asking people to see what they have not seen before,â€� Ms. Harris said in an email. â€œAs our government becomes more reflective of the people it represents and the voices at the table become more diverse, it is important for us to really check how we are creating and supporting an inclusive environment â€” and a big part of that is about how we use language.â€�\\r\\nOf course, one might argue thereâ€™s something of a feedback loop: The language reflects the culture. The culture wonâ€™t change until there is a winning candidate who upends the old biases. But those running for that spot may be impeded by the incessant talking about gender.\\r\\nThe researchers say the United Kingdom may provide an encouraging case study.\\r\\nIn 2017, they replicated the study there, in the lead-up to an election to determine the next prime minister.\\r\\nTheresa May was prime minister at the time and was expected to win â€” but she was not the first woman to hold that post. (That was Margaret Thatcher.)\\r\\nWhen referring to the next prime minister, the British study participants were more likely to use the pronoun â€œsheâ€� than â€œhe.â€�\\r\\nSharon Attia contributed research.\\r\\nCrÃ©dito: By Jessica BennettWord count: 1594Show lessYou have requested \"on-the-fly\" machine translation of selected content from our databases. This functionality is provided solely for your convenience and is in no way intended to replace human translation. Show full disclaimerNeither ProQuest nor its licensors make any representations or warranties with respect to the translations. The translations are automatically generated \"AS IS\" and \"AS AVAILABLE\" and are not retained in our systems. PROQUEST AND ITS LICENSORS SPECIFICALLY DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES FOR AVAILABILITY, ACCURACY, TIMELINESS, COMPLETENESS, NON-INFRINGMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Your use of the translations is subject to all use restrictions contained in your Electronic Products License Agreement and by using the translation functionality you agree to forgo any and all claims against ProQuest or its licensors for your use of the translation functionality and any output derived there from. Hide full disclaimer\\r\\n\\r\\nLonger documents can take a while to translate. Rather than keep you waiting, we have only translated the first few paragraphs. Click the button below if you want to translate the rest of the document.\\r\\nTranslate AllCopyright International New York Times Jan 27, 2020'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_All_Medias.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Preprocessing(corpus):\n",
    "    # convert string to list i.e. ['hide', 'highlightingfull', '[[missing']\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "\n",
    "    # lower case each item in the list, and remove non-alphabetic characters i.e. ['hide', 'highlightingfull', 'missing']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [re.sub(r'[^a-zA-Z]', \"\",y.lower()) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string and replace keywords containing the target names\n",
    "    keywords = ['new york times', 'the new york times', 'international new york times'\n",
    "                \"the washington post\", \"WP Company LLC\", \"washpostcom\",\n",
    "                'wall street journal', 'thomaswsjcom', 'Dow Jones Company Inc.']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x).replace(keyword, \"\") for keyword in keywords])\n",
    "\n",
    "    # stem each word in the text\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x)])\n",
    "\n",
    "    # convert list to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "\n",
    "    print(type(corpus.iloc[0]['text']))\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide highlightingful texttranslateundo transla...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hide highlightingabstracttranslateundo transla...</td>\n",
       "      <td>New York Times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           media\n",
       "0  hide highlightingful texttranslateundo transla...  New York Times\n",
       "1  hide highlightingabstracttranslateundo transla...  New York Times"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus = Data_Preprocessing(corpus_All_Medias)\n",
    "processed_corpus.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking\n",
    "processed_corpus.to_csv('processed_corpus.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Split training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973    hide highlightingful texttranslateundo transla...\n",
       "552    hide highlightingful texttranslateundo transla...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate features and targets\n",
    "X = processed_corpus.iloc[:, 0]\n",
    "y = processed_corpus.iloc[:, 1]\n",
    "\n",
    "# split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'New York Times': 0, 'The Washington Post': 1, 'Wall Street Journal': 2}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "# get label name mapping\n",
    "le.fit(y_train)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "# encode the target \n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Getting document term matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Create matrix of token counts using unigram, bigram and trigram tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram matrix of token counts\n",
    "\n",
    "def get_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range, binary=True) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram token counts matrix\n",
    "binary1_train, binary1_test = get_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram token counts matrix\n",
    "binary2_train, binary2_test = get_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram token counts matrix\n",
    "binary3_train, binary3_test = get_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in binary1_train is: 10507\n",
      "The unique terms in binary2_train is: 71483\n",
      "The unique terms in binary3_train is: 120599\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in binary1_train is:\", binary1_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary2_train is:\", binary2_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary3_train is:\", binary3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Create DTM using unigram, bigram and trigram term frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram term frequency matrix\n",
    "\n",
    "def get_TF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tf matrix\n",
    "tf1_train, tf1_test = get_TF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf matrix\n",
    "tf2_train, tf2_test = get_TF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf matrix\n",
    "tf3_train, tf3_test = get_TF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tf1_train is: 10507\n",
      "The unique terms in tf2_train is: 71483\n",
      "The unique terms in tf3_train is: 120599\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tf1_train is:\", tf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf2_train is:\", tf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf3_train is:\", tf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Create DTM using unigram, bigram and trigram TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram TF-IDF matrix\n",
    "\n",
    "def get_TF_IDF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tf-idf matrix\n",
    "tfidf1_train, tfidf1_test = get_TF_IDF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf-idf matrix\n",
    "tfidf2_train, tfidf2_test = get_TF_IDF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf-idf matrix\n",
    "tfidf3_train, tfidf3_test = get_TF_IDF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tfidf1_train is: 10507\n",
      "The unique terms in tfidf2_train is: 71483\n",
      "The unique terms in tfidf3_train is: 120599\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tfidf1_train is:\", tfidf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf2_train is:\", tfidf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf3_train is:\", tfidf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 XGBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model training\n",
    "def train_model(clf, dtm, test):\n",
    "    # train data\n",
    "    clf.fit(dtm, y_train)\n",
    "    \n",
    "    # Predicting on the test set\n",
    "    preds = clf.predict(test)\n",
    "    \n",
    "    # print evaluation matrix\n",
    "    print(\"Accuracy:\", '{:1.4f}'.format(accuracy_score(y_test, preds)))\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    return '{:1.4f}'.format(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Naive Bayes\n",
    "#clf = XGBClassifier() #MultinomialNB()\n",
    "#clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "param = {'max_depth': 3, 'eta': 0.3, 'objective':'multi:softmax', 'num_class': 3}\n",
    "xgb_clf = XGBClassifier(param)\n",
    "svm_clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "# reference: https://medium.com/@gabrielziegler3/multiclass-multilabel-classification-with-xgboost-66195e4d9f2d\n",
    "# reference: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "# Model Configurations\n",
    "binary1 = (\"unigram, binary\", binary1_train, binary1_test)\n",
    "binary2 = (\"bigram, binary\",  binary2_train, binary2_test)\n",
    "binary3 = (\"trigram, binary\", binary3_train, binary3_test)\n",
    "tf1 = (\"unigram, TF\", tf1_train, tf1_test)\n",
    "tf2 = (\"bigram, TF\",  tf2_train, tf2_test)\n",
    "tf3 = (\"trigram, TF\", tf3_train, tf3_test)\n",
    "tfidf1 = (\"unigram, TF-IDF\", tfidf1_train, tfidf1_test)\n",
    "tfidf2 = (\"bigram, TF-IDF\",  tfidf2_train, tfidf2_test)\n",
    "tfidf3 = (\"trigram, TF-IDF\", tfidf3_train, tfidf3_test)\n",
    "DTMs = [binary1, binary2, binary3,\n",
    "        tf1, tf2, tf3,\n",
    "        tfidf1, tfidf2, tfidf3]\n",
    "\n",
    "df = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = xgb_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config[2]):\n",
    "        best_config = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df = df.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unigram, binary</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigram, binary</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trigram, binary</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unigram, TF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigram, TF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trigram, TF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unigram, TF-IDF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigram, TF-IDF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trigram, TF-IDF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config  accuracy\n",
       "0  unigram, binary       1.0\n",
       "1   bigram, binary       1.0\n",
       "2  trigram, binary       1.0\n",
       "3      unigram, TF       1.0\n",
       "4       bigram, TF       1.0\n",
       "5      trigram, TF       1.0\n",
       "6  unigram, TF-IDF       1.0\n",
       "7   bigram, TF-IDF       1.0\n",
       "8  trigram, TF-IDF       1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of xgb classifier\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best Configuration:', 'unigram, binary', '1.0000', <1080x10507 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 359012 stored elements in Compressed Sparse Row format>, <270x10507 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 88076 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Configuration\n",
    "xgb_clf.fit(best_config[3], y_train)\n",
    "\n",
    "# predictions on the test data\n",
    "preds = xgb_clf.predict(best_config[4])\n",
    "\n",
    "# feature importance\n",
    "importances = xgb_clf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, ngram_range = (1,2), binary=True) \n",
    "vectorizer.fit(X_train)\n",
    "names = [vectorizer.get_feature_names()[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ani way',\n",
       " 'bloomberg gave',\n",
       " 'ambiti women',\n",
       " 'avalanch phone',\n",
       " 'accomplish chang',\n",
       " 'activ got',\n",
       " 'bloomberg great',\n",
       " 'beau biden',\n",
       " 'abandon hi',\n",
       " 'audiobook',\n",
       " 'advis support',\n",
       " 'candid didnt',\n",
       " 'acknowledg anyth',\n",
       " 'challeng ha',\n",
       " 'cassidi la',\n",
       " 'author discuss',\n",
       " 'accord parti',\n",
       " 'africanamerican conserv',\n",
       " 'agreement lawmr',\n",
       " 'allow use',\n",
       " 'addit',\n",
       " 'barrag',\n",
       " 'book research',\n",
       " 'build winneshiek',\n",
       " 'agreement mr',\n",
       " 'bring attent',\n",
       " 'break presid',\n",
       " 'best face',\n",
       " 'bubbl',\n",
       " 'ad accus',\n",
       " 'ad need',\n",
       " 'account told',\n",
       " 'ahead becaus',\n",
       " 'arm steve',\n",
       " 'aaron zitner',\n",
       " 'ani subpoena',\n",
       " 'activ wa',\n",
       " 'administr appear',\n",
       " 'adversari like',\n",
       " 'agenda sell',\n",
       " 'becam friend',\n",
       " 'affordablein hi',\n",
       " 'broader elector',\n",
       " 'bluer',\n",
       " 'bloomberg absenc',\n",
       " 'beat vice',\n",
       " 'campaign arm',\n",
       " 'begin trump',\n",
       " 'analyt said',\n",
       " 'care respons']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main features\n",
    "names[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 20\n",
    "\n",
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(num_features), importances[indices][0:num_features])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(num_features), names[0:num_features], rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 0.9963\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       0.99      1.00      0.99        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89  0  1]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 0.9963\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       0.99      1.00      0.99        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89  0  1]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       1.00      1.00      1.00        90\n",
      "           2       1.00      1.00      1.00        90\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 0.9481\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        90\n",
      "           1       0.98      0.93      0.95        90\n",
      "           2       0.91      0.99      0.95        90\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       270\n",
      "   macro avg       0.95      0.95      0.95       270\n",
      "weighted avg       0.95      0.95      0.95       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83  2  5]\n",
      " [ 2 84  4]\n",
      " [ 1  0 89]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 0.9667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        90\n",
      "           1       0.94      1.00      0.97        90\n",
      "           2       0.97      0.99      0.98        90\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       270\n",
      "   macro avg       0.97      0.97      0.97       270\n",
      "weighted avg       0.97      0.97      0.97       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[82  5  3]\n",
      " [ 0 90  0]\n",
      " [ 0  1 89]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 0.9815\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        90\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.98      1.00      0.99        90\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       270\n",
      "   macro avg       0.98      0.98      0.98       270\n",
      "weighted avg       0.98      0.98      0.98       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[85  3  2]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.8259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.64      0.73        90\n",
      "           1       0.73      0.99      0.84        90\n",
      "           2       0.96      0.84      0.90        90\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       270\n",
      "   macro avg       0.84      0.83      0.82       270\n",
      "weighted avg       0.84      0.83      0.82       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[58 30  2]\n",
      " [ 0 89  1]\n",
      " [11  3 76]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.7556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.54      0.67        90\n",
      "           1       0.61      1.00      0.76        90\n",
      "           2       1.00      0.72      0.84        90\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       270\n",
      "   macro avg       0.82      0.76      0.75       270\n",
      "weighted avg       0.82      0.76      0.75       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[49 41  0]\n",
      " [ 0 90  0]\n",
      " [ 8 17 65]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.8185\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72        90\n",
      "           1       0.67      1.00      0.80        90\n",
      "           2       1.00      0.87      0.93        90\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       270\n",
      "   macro avg       0.86      0.82      0.82       270\n",
      "weighted avg       0.86      0.82      0.82       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53 37  0]\n",
      " [ 0 90  0]\n",
      " [ 5  7 78]]\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm classifier\n",
    "df_svm = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config_svm = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = svm_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config_svm[2]):\n",
    "        best_config_svm = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df_svm = df_svm.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unigram, binary</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigram, binary</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trigram, binary</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unigram, TF</td>\n",
       "      <td>0.9481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigram, TF</td>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trigram, TF</td>\n",
       "      <td>0.9815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unigram, TF-IDF</td>\n",
       "      <td>0.8259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigram, TF-IDF</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trigram, TF-IDF</td>\n",
       "      <td>0.8185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config  accuracy\n",
       "0  unigram, binary    0.9963\n",
       "1   bigram, binary    0.9963\n",
       "2  trigram, binary    1.0000\n",
       "3      unigram, TF    0.9481\n",
       "4       bigram, TF    0.9667\n",
       "5      trigram, TF    0.9815\n",
       "6  unigram, TF-IDF    0.8259\n",
       "7   bigram, TF-IDF    0.7556\n",
       "8  trigram, TF-IDF    0.8185"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of svm classifier\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best Configuration:', 'trigram, binary', '1.0000', <1080x120599 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1006998 stored elements in Compressed Sparse Row format>, <270x120599 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 213614 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "print(best_config_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
