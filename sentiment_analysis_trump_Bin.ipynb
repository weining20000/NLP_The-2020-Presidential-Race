{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sa/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - py-xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  anaconda\n",
      "    ca-certificates-2020.1.1   |                0         132 KB  anaconda\n",
      "    certifi-2019.11.28         |           py37_0         156 KB  anaconda\n",
      "    conda-4.8.3                |           py37_0         3.0 MB  anaconda\n",
      "    libxgboost-0.90            |       h0a44026_1         2.4 MB  anaconda\n",
      "    openssl-1.1.1d             |       h1de35cc_4         3.4 MB  anaconda\n",
      "    py-xgboost-0.90            |   py37h0a44026_1          77 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  anaconda/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         anaconda/osx-64::libxgboost-0.90-h0a44026_1\n",
      "  py-xgboost         anaconda/osx-64::py-xgboost-0.90-py37h0a44026_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                       pkgs/main::conda-4.8.2-py37_0 --> anaconda::conda-4.8.3-py37_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates                                 pkgs/main --> anaconda\n",
      "  certifi                                         pkgs/main --> anaconda\n",
      "  openssl                                         pkgs/main --> anaconda\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.8.3          | 3.0 MB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 3.4 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "ca-certificates-2020 | 132 KB    | ##################################### | 100% \n",
      "libxgboost-0.90      | 2.4 MB    | ##################################### | 100% \n",
      "py-xgboost-0.90      | 77 KB     | ##################################### | 100% \n",
      "certifi-2019.11.28   | 156 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# conda install -c anaconda py-xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sa/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB\n",
      "    ca-certificates-2020.1.1   |                0         125 KB\n",
      "    certifi-2019.11.28         |           py37_0         153 KB\n",
      "    conda-4.8.3                |           py37_0         2.8 MB\n",
      "    openssl-1.1.1d             |       h1de35cc_4         2.2 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.3 MB\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  python_abi-3.7-1_cp37m\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  _py-xgboost-mutex                                anaconda --> pkgs/main\n",
      "  ca-certificates                                  anaconda --> pkgs/main\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "  conda              conda-forge::conda-4.8.3-py37hc8dfbb8~ --> pkgs/main::conda-4.8.3-py37_0\n",
      "  openssl                                          anaconda --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.8.3          | 2.8 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "certifi-2019.11.28   | 153 KB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 125 KB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.2 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: - \n",
      "Warning: 4 possible package resolutions (only showing differing packages):\n",
      "  - anaconda/osx-64::ca-certificates-2020.1.1-0, anaconda/osx-64::openssl-1.1.1d-h1de35cc_4\n",
      "  - anaconda/osx-64::openssl-1.1.1d-h1de35cc_4, defaults/osx-64::ca-certificates-2020.1.1-0\n",
      "  - anaconda/osx-64::ca-certificates-2020.1.1-0, defaults/osx-64::openssl-1.1.1d-h1de35cc_4\n",
      "  - defaults/osx-64::ca-certificates-2020.1.1-0, defaults/osx-64::openssl-1.1.1d-h1de35ccdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sa/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
      "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
      "    libxgboost-0.90            |       h6de7cb9_1         2.4 MB  conda-forge\n",
      "    py-xgboost-0.90            |   py37h6de7cb9_1          71 KB  conda-forge\n",
      "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
      "    xgboost-0.90               |   py37h6de7cb9_1           9 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.7-1_cp37m\n",
      "  xgboost            conda-forge/osx-64::xgboost-0.90-py37h6de7cb9_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                        anaconda::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                          anaconda --> conda-forge\n",
      "  libxgboost           anaconda::libxgboost-0.90-h0a44026_1 --> conda-forge::libxgboost-0.90-h6de7cb9_1\n",
      "  py-xgboost         anaconda::py-xgboost-0.90-py37h0a4402~ --> conda-forge::py-xgboost-0.90-py37h6de7cb9_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libxgboost-0.90      | 2.4 MB    | ##################################### | 100% \n",
      "py-xgboost-0.90      | 71 KB     | ##################################### | 100% \n",
      "python_abi-3.7       | 4 KB      | ##################################### | 100% \n",
      "conda-4.8.3          | 3.0 MB    | ##################################### | 100% \n",
      "xgboost-0.90         | 9 KB      | ##################################### | 100% \n",
      "certifi-2019.11.28   | 148 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.2-cp37-cp37m-macosx_10_9_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: requests in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.12.48-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.16.0,>=1.15.48\n",
      "  Downloading botocore-1.15.48-py2.py3-none-any.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "  Using cached s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/sa/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.48->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=a678d64f8d39a5bc4cf3eb20ed5183aa0dc233b2de8a3818c368bb5ebc1499f5\n",
      "  Stored in directory: /Users/sa/Library/Caches/pip/wheels/bb/1c/9c/412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed boto3-1.12.48 botocore-1.15.48 docutils-0.15.2 gensim-3.8.2 jmespath-0.9.5 s3transfer-0.3.3 smart-open-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modeling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stopwords_english = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.read_csv('/Users/sa/Desktop/NLP_The-2020-Presidential-Race-master-2/Data/All_Candidates/Donald_Trump.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Annotate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hide highlightingFull TextTranslateUndo Translation FromToTranslateTranslation in progress... \\n\\n[[missing key: loadingAnimation]]The full text may take 40-120 seconds to translate; larger documents may take longer.\\n\\nCancel\\nOverlayEndTurn on search term navigationTurn on search term navigation\\n| Jump to first hit\\nPresident Trump delivered a straightforward message to the millions of football fans watching the Super Bowl on Sunday: \"The best is yet to come,\" he declared in a campaign ad that ran after the game.\\nBut exactly what comes next for Mr. Trump if he wins a second term is still under discussion at the White House, even as the president plans to continue crisscrossing the nation campaigningâ€”now\\nwith a Senate acquittal\\n, rising approval ratings and increased confidence in his re-election prospects.\\nSenior aidesâ€”led by Chris Liddell, the White House\\'s deputy chief of staff for policy coordinationâ€”have been meeting since late last year to chart an agenda for the second term, according to administration officials. The discussions are in their initial stages, the officials said.\\nThe early outlines of the agenda are starting to emerge, but aides said Mr. Trump hasn\\'t yet signed off on the final details of the plan, though he is receiving regular briefings on the discussions. Among the issues under consideration: continuing the administration\\'s efforts to lower prescription drug prices, pushing for a broad infrastructure bill and taking another crack at reforming the country\\'s immigration system, the officials said. White House aides are still holding out hope that some of these things can get accomplished before the end of the first term, but lawmakers and some in the administration are pessimistic about the chances of finding common ground with Democratic lawmakers this year.\\nSenior aides have also begun discussing ways to lower the deficitâ€”which is projected to reach $1 trillion in 2020â€”and cut taxes for the middle class, as well as roll back more Obama-era regulations. The president\\'s coming budget blueprint, set to be released Monday, is expected to shed more light on his policy priorities.\\nSome in the administration have said privately that Mr. Trump should be doing more to sell voters on his second-term agenda. But others countered that developing a detailed term-two agenda is complicated by uncertainty about the balance of power in Congress in 2021; the White House could be much more aggressive in its legislative proposals if Republicans controlled both chambers.\\nDeputy-level aides from key White House offices gathered at Camp David early last month to discuss the major policy themes they hope to focus on for the rest of 2020 and in the first year of a second term, the officials said. Additional meetings are expected in the coming months.\\nMr. Trump hasn\\'t yet publicly articulated a detailed policy vision for a second term during his frequent campaign rallies and speeches, instead pointing to his first-term record and warning that a Democratic president would blow it all up.\\nAt his State of the Union address Tuesday, Mr. Trump made clear that\\nthe economy will be the core theme\\nof his re-election campaign. Ticking through a list of economic statistics, the president took credit for the U.S.\\'s economic boom and suggested it could all go away if he is denied four more years in the White House.\\nHealth care and education were among the other policy issues Mr. Trump discussed during the speech. He called on Congress to pass legislation that would establish a tax credit meant to encourage wealthy individuals and corporations to provide scholarships to help low-income students afford private or religious schools. The bill, sponsored by Sen. Ted Cruz (R., Texas), hasn\\'t moved forward in the Senate and is unlikely to gain traction in the Democratic-controlled House.\\nBut Mr. Trump has spent more time looking back on the past three years than looking ahead to his possible second term.\\nDuring a rally in Des Moines, Iowa, last week, the president vowed to usher in a Republican Congress to enact new immigration policies, negotiate new trade deals, offer an alternative to Obamacare and usher in new breakthroughs in science to cure childhood cancers and end the AIDS epidemic.\\nThe bulk of his remarks focused on what he sees as the threat Democrats pose to the country.\\n\"In short, this election is a choice between American freedom and Democratic socialism, and in some cases, in my opinion, it\\'s worse than socialism,\" he said. \"Socialism is a kind word by comparison.\"\\nSHARE YOUR THOUGHTS\\nWhat policy issues do you think President Trump should focus on if he wins a second term? Join the conversation below.\\nMr. Trump\\'s advisers say drawing a contrast with Democrats is a winning strategy. Some of them believe the president\\'s appeal to his devoted base stems less from his specific policy positions and more from his image as a political outsider who is taking on Washington\\'s elite.\\nAnd some longtime political strategists agree.\\n\"He ran as the disrupter in chief; has governed as the disrupter in chief, and will run for re-election as the disrupter in chief,\" said Chris Lehane, a former adviser to Bill Clinton and Al Gore. \"You could even make an argument that the less he sounds like a typical, conventional politician, including having a typical conventional agenda, the more he\\'s on message.\"\\nThe president\\'s advisers also believe Mr. Trump has a strong record to run on. As a result, much of Mr. Trump\\'s campaign trail rhetoric looks back on his first-term accomplishments, from criminal justice legislation to the trade deals he struck with China, Mexico and Canada, to the strong economy.\\n\"The election will be a stark study in contrasts, between the Democrats who offer massive government intervention into people\\'s lives and President Trump who promotes liberty, economic freedom, and prosperity,\" Trump campaign spokesman Tim Murtaugh said in a statement.\\nVeterans of past administrations and presidential campaigns said Mr. Trump\\'s first-term performance is what many voters care about the most.\\n\"If they\\'re voting for the president, they\\'re likely picking the president for retrospective reasons,\" said Lanhee Chen, who served as the policy director to Mitt Romney\\'s 2012 presidential campaign. \"It\\'s much more important for the challenger to define their agenda, than the incumbent.\"\\nMr. Chen nonetheless suggested Mr. Trump opens himself up to criticism from his opponents for not laying out a detailed agenda for the second term. During the 2012 election, for example, Mr. Romney repeatedly called on Barack Obama to flesh out his agenda, arguing he wasn\\'t saying enough about what he would do if he won four more years in office.\\n\"They have no agenda for the future, no agenda for America, no agenda for a second term,\" Mr. Romney said during an October 2012 rally.\\nSome past presidents have outlined detailed visions for a second term as they campaigned for re-election. Bill Clinton, for example, called for a \"bridge to the 21st century\" in 1996, which included a plan to help welfare recipients get jobs. But other presidents have taken a similar approach to Mr. Trump by emphasizing the economic success of their first term, as Ronald Reagan did in his \"Morning in America\" advertising campaign.\\nCecilia MuÃ±oz, who led the White House Domestic Policy Council for the last five years of the Obama administration, said senior aides were having in-depth conversations about a second term at this point in Mr. Obama\\'s presidency.\\n\"The conversations were robust. We were an administration of planners,\" she said, adding, \"There was a time when you had a president with a clear vision and a team expected to plan for that vision.\"\\nWrite to Andrew Restuccia at\\nAndrew.Restuccia@wsj.com\\n\\nCredit: By Andrew Restuccia Word count: 1221Show lessYou have requested \"on-the-fly\" machine translation of selected content from our databases. This functionality is provided solely for your convenience and is in no way intended to replace human translation. Show full disclaimerNeither ProQuest nor its licensors make any representations or warranties with respect to the translations. The translations are automatically generated \"AS IS\" and \"AS AVAILABLE\" and are not retained in our systems. PROQUEST AND ITS LICENSORS SPECIFICALLY DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES FOR AVAILABILITY, ACCURACY, TIMELINESS, COMPLETENESS, NON-INFRINGMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Your use of the translations is subject to all use restrictions contained in your Electronic Products License Agreement and by using the translation functionality you agree to forgo any and all claims against ProQuest or its licensors for your use of the translation functionality and any output derived there from. Hide full disclaimer\\n\\nLonger documents can take a while to translate. Rather than keep you waiting, we have only translated the first few paragraphs. Click the button below if you want to translate the rest of the document.\\nTranslate AllCopyright 2020 Dow Jones & Company, Inc. All Rights Reserved.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['text'][355]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trump's Second-Term Agenda Still on the Drawing Board; The president rarely discusses what he would do if he wins another term, but his advisers have begun to sketch out ideas\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['title'][355]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand annotation indicies\n",
    "# positive = [320, 321, 323, 324, 326, 344, 346, 348, 349, 355]\n",
    "\n",
    "# negative = [1, 2, 3, 6, 7, 9, 10, 11, 12, 17, 18, 100, 332]\n",
    "\n",
    "# neutral = [0, 4, 5, 8, 13, 14, 15, 16, 19, 300, 310, 325, 328, 341, 352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_trump = [447,408, 395, 389, 377, 374, 372, 320, 321, 323, 324, 326, 344, 346, 348, 349, 355, 106, 338, 419]\n",
    "\n",
    "negative_trump = [448, 396, 394, 1, 2, 3, 6, 7, 9, 10, 11, 12, 17, 18, 100, 332, 120, 29, 30, 36, 48]\n",
    "\n",
    "neutral_trump = [443, 432, 418, 398, 373, 365, 364, 4, 5, 8, 14, 16, 19, 253, 300, 310, 325, 328, 341, 352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new col for sentiment\n",
    "\n",
    "trump['sentiment'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate rows in new col with corresponding sentiment\n",
    "\n",
    "for i in trump.index:\n",
    "    for j in positive:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'pos'\n",
    "            \n",
    "for i in trump.index:\n",
    "    for j in neutral:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'neutral'\n",
    "            \n",
    "for i in trump.index:\n",
    "    for j in negative:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select text and news company names\n",
    "trump_sentiment = trump[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create corpus for each sentiment\n",
    "\n",
    "def create_corpus(trump_sentiment, sentiment_name):\n",
    "    \n",
    "    df1 = trump_sentiment.loc[trump_sentiment['sentiment'] == sentiment_name]\n",
    "    #df2 = Sanders_news.loc[Sanders_news['media'] == media_name]\n",
    "    #df3 = Trump_news.loc[Trump_news['media'] == media_name]\n",
    "    #frames = [df1, df2, df3]\n",
    "    #df = pd.concat(frames, ignore_index = True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small corpus for each sentiment\n",
    "POS = create_corpus(trump_sentiment, sentiment_name = 'pos')\n",
    "NEG = create_corpus(trump_sentiment, sentiment_name = 'neg')\n",
    "NEUTRAL = create_corpus(trump_sentiment, sentiment_name = 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "1  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "2  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "3  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "4  Hide highlightingFull TextTranslateUndo Transl...       pos"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_All_sentiment = pd.concat([POS, NEG, NEUTRAL], axis = 0, ignore_index = True)\n",
    "corpus_All_sentiment.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hide highlightingFull TextTranslateUndo Translation FromToTranslateTranslation in progress... \\n\\n[[missing key: loadingAnimation]]The full text may take 40-120 seconds to translate; larger documents may take longer.\\n\\nCancel\\nOverlayEndTurn on search term navigationTurn on search term navigation\\n| Jump to first hit\\nOXON HILL, Md.â€”The impeachment of President Trump motivated her to fly up from Texas, but after a half day at the Conservative Political Action Conference, Cathie Broten was convinced a more sinister force is in play.\\n\"It\\'s like Custer\\'s Last Stand: the Republicans vs. the socialists,\" said Ms. Broten, 70 years old, wearing a pin reading, \"Kiss me, I\\'m a capitalist.\"\\n\"We need to stand up and fight,\" she said Thursday. \"Somebody\\'s got to pay for the free TV, the free college. It\\'s time to draw the line.\"\\nWhile Mr. Trump is certain to be greeted by rapturous applause when he addresses CPAC on Saturday afternoon, another name has featured as prominently as the president\\'s during the four-day conference in suburban Washington: Sen. Bernie Sanders, the self-described democratic socialist and front-runner for the Democratic presidential nomination.\\n\"I have two words for you: Socialism sucks,\" Trump campaign adviser Mercedes Schlapp told an audience of hundreds. \"We have to stop it in its tracks.\"\\nThe CPAC themeâ€”America vs. Socialismâ€”reveals how Republicans plan to frame the November election, with or without Mr. Sanders as the nominee. Repeatedly, speakers portrayed the Democrats\\' agenda on health care, the environment, college tuition and other issues as an attempt to radically transform America.\\n\"Donald Trump and his allies are getting a little bit nervous about facing Sen. Sanders in a general election, and they\\'re all quickly realizing that the only way to attack someone who spent his entire life standing with the working class is to lie,\" said Sanders campaign spokesman Mike Casca.\\nAmid the \"crazy Bernie\" and communist Cuba references at CPAC were warnings about being overconfident.\\n\"Get your laughs out of the way and get the mockery out of the way and then get deathly serious,\" said the young conservative activist Charlie Kirk. \"Because we should not do what the left did in 2016 and dismiss an outsider populist candidate from thinking that person can\\'t win the White House.\"\\nSHARE YOUR THOUGHTS\\nHow can President Trump\\'s relationship with CPAC benefit him during the 2020 election season? Join the conversation below.\\nWhen Mr. Trump spoke at CPAC in 2011, saying he might run for president the following year, many in the Republican establishment laughed it off as a publicity grab. He skipped it in 2016 while some conservatives still fought to prevent his march to the nomination.\\nThis year showed how Mr. Trump commands the GOP, injecting his own sense of grievance and fight. The mere mention of Mitt Romney, the party\\'s 2012 nominee who\\nvoted earlier this month in the Senate to convict Mr. Trump\\non one article of impeachment, brought boos. Conference-goers stuffed ballot boxes to judge the \"phoniest\" conservative, picking from a list of other Republicans who have criticized Mr. Trump.\\nBefore noon on Thursday, attendees had sat through four panels focused on \"the coup,\" with speakers dismissing the impeachment and other investigations into Mr. Trump as the work of Democrats and a bureaucratic deep state.\\n\"They\\'re never going to stop,\" said Rep. Jim Jordan of Ohio. \"They tried to overturn the will of 63 million Americansâ€”all of us who voted for President Trump.\"\\nDemocrats hit back at claims like Mr. Jordan\\'s, calling it \"the oldest trick in the GOP playbook.\"\\n\"Republicans are trying to distract because they know they can\\'t win on the issues. In 2017, 2018 and 2019 Democrats won on a message of expanding access to health care,\" said Daniel Wessel, a Democratic National Committee spokesman.\\nIn addition to panels, actors Dean Cain and Kristy Swanson performed a dramatic reading of anti-Trump text messages between former FBI agents Peter Strzok and Lisa Page, favorite targets of Mr. Trump in his complaints about the investigation into Russian interference in the 2016 election.\\nThe CPAC gathering in past years was animated by Ron Paul-style libertarians; now it is dominated by Trump loyalists in red MAGA hats as the president continues to redefine the GOP on foreign policy and trade. There was little mention of the ballooning national debt.\\nFor some, it was a venue to apologize for being wrong about Mr. Trump in 2016.\\n\"Look, I was late to the Trump train,\" said Sen. Mike Lee of Utah. \"I was about as late as one can be. I had my doubts about whether he was a conservative. I had my doubts about whether he was electable.\" But Mr. Lee said the president has followed through on his promises, including moving the U.S. Embassy in Israel to Jerusalem, slashing regulations and nominating conservative judges.\\nVice President Mike Pence ticked off those accomplishments and the strong economy and\\ndeclared victory over the impeachment\\n. \"President Donald Trump was acquitted forever,\" he said to wild cheers. Like others, Mr. Pence acknowledged the appeal of Mr. Sanders\\'s policy proposals to young people in particular and said Republicans must engage them and explain the differences between \"freedom and socialism.\"\\n\"We definitely need to a better job of reaching young people and address their concerns,\" said Alexander Bowles, 18, of St. Louis, who said Mr. Trump also should moderate the way he speaks to avoid losing more suburban voters.\\nOutside the ballroom, people who have become celebrities in the Trump era were flocked by fans. Biceps poking from a black T-shirt, the Fox News regular Dan Bongino posed for selfies. Nigel Farage, one of Brexit\\'s most-visible architects, was greeted with applause as he rode down an escalator holding a wooden doll depicting Mr. Trump.\\nVendors sold Trump hats, towels, T-shirts and pins. A red-white-and-blue hammock with the word \"Deplorable\" was being offered at 10% off the $499 price tag with an extra 10% discount for anyone from a battleground state.\\nAt a booth sponsored by the NRA, young activists posed with cutouts of a diminutive Michael Bloomberg, a nod to Mr. Trump\\'s nickname for the Democratic presidential contenderâ€”\"mini Mike.\"\\nMr. Trump is scheduled to address CPAC at 3 p.m. Saturday. Last year he took the stage, hugged an American flag and delivered a speech that lasted more than two hours.\\nWrite to Alex Leary at\\nalex.leary@wsj.com\\n\\nCredit: By Alex Leary Word count: 1013Show lessYou have requested \"on-the-fly\" machine translation of selected content from our databases. This functionality is provided solely for your convenience and is in no way intended to replace human translation. Show full disclaimerNeither ProQuest nor its licensors make any representations or warranties with respect to the translations. The translations are automatically generated \"AS IS\" and \"AS AVAILABLE\" and are not retained in our systems. PROQUEST AND ITS LICENSORS SPECIFICALLY DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES FOR AVAILABILITY, ACCURACY, TIMELINESS, COMPLETENESS, NON-INFRINGMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Your use of the translations is subject to all use restrictions contained in your Electronic Products License Agreement and by using the translation functionality you agree to forgo any and all claims against ProQuest or its licensors for your use of the translation functionality and any output derived there from. Hide full disclaimer\\n\\nLonger documents can take a while to translate. Rather than keep you waiting, we have only translated the first few paragraphs. Click the button below if you want to translate the rest of the document.\\nTranslate AllCopyright 2020 Dow Jones & Company, Inc. All Rights Reserved.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_All_sentiment.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(set(stopwords.words('english')))\n",
    "more_words = ['Mr.', '--', 'highlightingFull', '-', '_', 'In', \"Ms.\", 'but', 'First', 'one', 'keep', \"The\", 'said',\n",
    "              'TextTranslateUndo','Translation',  'FromToTranslateTranslation',  'progress...',  '[[missing',  'key:',  \n",
    "              'loadingAnimation]]The',  'full',  'text',  'may',  'take',  '40-120',  'seconds',  'translate;',  'larger',  \n",
    "              'documents',  'may',  'take',  'longer.',  'Cancel',  'OverlayEndTurn',  'search',  'term',  'navigationTurn',  \n",
    "              'search',  'term',  'navigation',  '|',  'Jump',  'first',  'hitWith',  \"president's\", 'And', 'could', 'going',\n",
    "              'get', 'FOR', 'would', 'president', 'But', 'AND', 'I', \"ANY\", 'AS', 'OR', 'He', \"Trump's\", 'also', 'use', 'make',\n",
    "              '\"AS', 'hide', 'two', 'want', 'way', 'even', 'last', 'said', 'said,', 'said.', 'A', 'made', 'time', 'using', \n",
    "              'Trump,', 'BY', 'ProQuest', 'licensors', 'translations', 'NEW', 'YORK', 'Times', 'New', 'York', 'think', 'This',\n",
    "              'including', 'told', \"The'\", \"Hide'\", 'Mr', 'translation', \"I'\", \"but'\", \"s'\", \"In'\", \"It'\", \"much'\", \"He'\",\n",
    "              'functionality', \"'|\", '*', \"'I\", '.', 'Washinton', 'Post', 'washpost', 'com', 'wsj', '/\"', 'mr', 'm', 'a', 'mr.',\n",
    "              'ms.', \"new\", \"a\", \"york\", \"a\", \"proquest\", \"Hide\", \"highlighting\", \"Full\", \"Text\", \"Translate\", \"Undo\", \n",
    "              \"Translation\", \"From\", \"To\", \"TranslateTranslation\", \"in\", \"progress\", \"[\", \"missing\", \"key\", \":\",\n",
    "              \"loadingAnimation\", \"]\", \"may\", \"take\", \"seconds\", \"translate\", \"larger\", \"documents\", \"longer\", \"Cancel\",\n",
    "              \"OverlayEndTurn\", \"Turn\", \"on\", \"search\", \"term\", \"navigation\", \"navigation\", \"Jump\", \"to\", \"first\", \"hit\",\n",
    "              \"(\", \"PHOTOGRAPHS\", \"BY\" \"ASSOCIATED\", \"PRESS\", \"Word\", \"count\", \"Show\", \"less\", \"You\", \"have\", \"requested\",\n",
    "               \"on-the-fly\", \"machine\", \"translation\", \"selected\", \"content\", \"from\", \"our\", \"databases\", \"This\", \n",
    "              \"functionality\", \"provided\", \"solely\", \"your\", \"convenience\", \"no\", \"way\", \"intended\", \"replace\", \"human\",\n",
    "              \"Show\", \"disclaimer\", \"Neither\", \"ProQuest\", \"nor\", \"its\", \"licensors\", \"make\", \"any\", \"representations\",\n",
    "              \"warranties\", \"with\", \"respect\", \"translations\", \"are\", \"automatically\", \"generated\", \"retained\", \"systems\"\n",
    "              \"PROQUEST\", \"LICENSORS\", \"SPECIFICALLY\", \"DISCLAIM\", \"ANY\", \"ALL\", \"EXPRESS\", \"OR\", \"IMPLIED\", \"WARRANTIES\",\n",
    "              \"INCLUDING\", \"WITHOUT\", \"LIMITATION\", \"AVAILABILITY\", \"ACCURACY\", \"TIMELINESS\", \"COMPLETENESS\", \"NON-INFRINGMENT\", \n",
    "              \"MERCHANTABILITY\", \"FITNESS\", \"PARTICULAR\", \"PURPOSE\", \"use\", \"restrictions\", \"contained\", \"Electronic\",\n",
    "              \"Products\", \"License\", \"Agreement\", \"agree\", \"forgo\", \"claims\", \"against\", \"ProQuest\", \"output\", \"derived\",\n",
    "              \"there\", \"from\", \"disclaimer\", \"Longer\", \"documents\", \"while\", \"Rather\", \"than\", \"keep\", \"you\", \"waiting\", \n",
    "              \"we\", \"have\", \"only\", \"translated\", \"paragraphs\", \"Click\", \"button\", \"below\", \"rest\", \"document\", \"Translate\",\n",
    "              \"AllCopyright\", \"Company\", \"fly\", 'systems', 'NON', 'part', 'lessYou', 'week', 'many', 'say', 'year', 'day',\n",
    "              'INFRINGMENT', 'AVAILABLE', 'disclaimerNeither', 'back', 'whether', 'much', 'still', 'since', 'then', 'according',\n",
    "              'come', 'thing', 'know', 'see', \"saying\", 'still', 'subject', 'PROQUEST', 'highlightingfull', 'texttranslateundo',\n",
    "              'fromtotranslatetranslation', 'loadinganimationthe', 'cancel', 'overlayendturn', 'navigationturn', 'jump', \n",
    "              'hitwith', 'ad', 'like', 'highlightingFull', \"TextTranslateUndo\", 'Translation','FromToTranslateTranslation'\n",
    "              'progress', 'missing', 'key', 'loadingAnimation', 'seconds', 'navigationTurn', 'search', 'term'\n",
    "              ]\n",
    "more_stop_words = stop_words + more_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Preprocessing(corpus):\n",
    "    # convert string to list i.e. ['hide', 'highlightingfull', '[[missing']\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "    \n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [item for item in x if item not in more_stop_words])\n",
    "    \n",
    "    # lower case each item in the list, and remove non-alphabetic characters i.e. ['hide', 'highlightingfull', 'missing']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [re.sub(r'[^a-zA-Z]', \"\",y.lower()) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string and replace keywords containing the target names\n",
    "#     keywords = ['new york times', 'the new york times', 'international new york times'\n",
    "#                 \"the washington post\", \"WP Company LLC\", \"washpostcom\",\n",
    "#                 'wall street journal', 'thomaswsjcom', 'Dow Jones Company Inc.']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x)])\n",
    "\n",
    "    # stem each word in the text\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x)])\n",
    "\n",
    "    # convert list to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "\n",
    "    print(type(corpus.iloc[0]['text']))\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oxon hill mdthe impeach presid trump motiv tex...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washingtonin three year offic presid trump ove...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rancho mirag calif republican senat face tight...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washingtonpresid trump major nation audienc pa...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>davo switzerlandpresid trump tout describ blue...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  oxon hill mdthe impeach presid trump motiv tex...       pos\n",
       "1  washingtonin three year offic presid trump ove...       pos\n",
       "2  rancho mirag calif republican senat face tight...       pos\n",
       "3  washingtonpresid trump major nation audienc pa...       pos\n",
       "4  davo switzerlandpresid trump tout describ blue...       pos"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentiment_corpus = Data_Preprocessing(corpus_All_sentiment)\n",
    "processed_sentiment_corpus[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Split training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    hitth public struggl white hous advis kellyann...\n",
       "32    presid trump end strong economi string domest ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate features and targets\n",
    "X = processed_sentiment_corpus.iloc[:, 0]\n",
    "y = processed_sentiment_corpus.iloc[:, 1]\n",
    "\n",
    "# split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0, 'neutral': 1, 'pos': 2}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "# get label name mapping\n",
    "le.fit(y_train)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "# encode the target \n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Getting document term matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Create matrix of token counts using unigram, bigram and trigram tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram matrix of token counts\n",
    "\n",
    "def get_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range, binary=True) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram token counts matrix\n",
    "binary1_train, binary1_test = get_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram token counts matrix\n",
    "binary2_train, binary2_test = get_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram token counts matrix\n",
    "binary3_train, binary3_test = get_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in binary1_train is: 1137\n",
      "The unique terms in binary2_train is: 1473\n",
      "The unique terms in binary3_train is: 1568\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in binary1_train is:\", binary1_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary2_train is:\", binary2_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary3_train is:\", binary3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Create DTM using unigram, bigram and trigram term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram term frequency matrix\n",
    "\n",
    "def get_TF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tf matrix\n",
    "tf1_train, tf1_test = get_TF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf matrix\n",
    "tf2_train, tf2_test = get_TF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf matrix\n",
    "tf3_train, tf3_test = get_TF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tf1_train is: 1137\n",
      "The unique terms in tf2_train is: 1473\n",
      "The unique terms in tf3_train is: 1568\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tf1_train is:\", tf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf2_train is:\", tf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf3_train is:\", tf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Create DTM using unigram, bigram and trigram TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram TF-IDF matrix\n",
    "\n",
    "def get_TF_IDF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unigram tf-idf matrix\n",
    "tfidf1_train, tfidf1_test = get_TF_IDF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf-idf matrix\n",
    "tfidf2_train, tfidf2_test = get_TF_IDF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf-idf matrix\n",
    "tfidf3_train, tfidf3_test = get_TF_IDF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tfidf1_train is: 1137\n",
      "The unique terms in tfidf2_train is: 1473\n",
      "The unique terms in tfidf3_train is: 1568\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tfidf1_train is:\", tfidf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf2_train is:\", tfidf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf3_train is:\", tfidf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model training\n",
    "def train_model(clf, dtm, test):\n",
    "    # train data\n",
    "    clf.fit(dtm, y_train)\n",
    "    \n",
    "    # Predicting on the test set\n",
    "    preds = clf.predict(test)\n",
    "    \n",
    "    # print evaluation matrix\n",
    "    print(\"Accuracy:\", '{:1.4f}'.format(accuracy_score(y_test, preds)))\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    return '{:1.4f}'.format(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 0.8750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.89      0.89      0.87         8\n",
      "weighted avg       0.92      0.88      0.88         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 0 1]\n",
      " [0 3 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 0.8750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.89      0.89      0.87         8\n",
      "weighted avg       0.92      0.88      0.88         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 0 1]\n",
      " [0 3 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.81      0.78      0.72         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 1]\n",
      " [0 3 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.61      0.67      0.62         8\n",
      "weighted avg       0.60      0.62      0.60         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 1]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.61      0.67      0.62         8\n",
      "weighted avg       0.60      0.62      0.60         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 1]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.61      0.67      0.62         8\n",
      "weighted avg       0.60      0.62      0.60         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 1 1]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.78      0.78      0.78         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 1 0]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.50      0.67      0.57         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.67      0.67      0.66         8\n",
      "weighted avg       0.62      0.62      0.61         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.50      0.67      0.57         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.67      0.67      0.66         8\n",
      "weighted avg       0.62      0.62      0.61         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [1 2 0]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Naive Bayes\n",
    "clf = XGBClassifier() #MultinomialNB()\n",
    "clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "#param = {'max_depth': 3, 'eta': 0.3, 'objective':'multi:softmax', 'num_class': 3}\n",
    "# param = {'max_depth': 3, 'learning_rate ': 0.3, 'objective':'multi:softmax'}\n",
    "#xgb_clf = XGBClassifier(param)\n",
    "#xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.3, objective='multi:softmax')\n",
    "xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.3, objective='multi:softmax', num_class=3)\n",
    "svm_clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "# reference: https://medium.com/@gabrielziegler3/multiclass-multilabel-classification-with-xgboost-66195e4d9f2d\n",
    "# reference: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "# Model Configurations\n",
    "binary1 = (\"unigram, binary\", binary1_train, binary1_test)\n",
    "binary2 = (\"bigram, binary\",  binary2_train, binary2_test)\n",
    "binary3 = (\"trigram, binary\", binary3_train, binary3_test)\n",
    "tf1 = (\"unigram, TF\", tf1_train, tf1_test)\n",
    "tf2 = (\"bigram, TF\",  tf2_train, tf2_test)\n",
    "tf3 = (\"trigram, TF\", tf3_train, tf3_test)\n",
    "tfidf1 = (\"unigram, TF-IDF\", tfidf1_train, tfidf1_test)\n",
    "tfidf2 = (\"bigram, TF-IDF\",  tfidf2_train, tfidf2_test)\n",
    "tfidf3 = (\"trigram, TF-IDF\", tfidf3_train, tfidf3_test)\n",
    "DTMs = [binary1, binary2, binary3,\n",
    "        tf1, tf2, tf3,\n",
    "        tfidf1, tfidf2, tfidf3]\n",
    "\n",
    "df = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = xgb_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config[2]):\n",
    "        best_config = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df = df.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.43      1.00      0.60         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.48      0.44      0.37         8\n",
      "weighted avg       0.54      0.50      0.41         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 2 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# svm classifier\n",
    "df_svm = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config_svm = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = svm_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config_svm[2]):\n",
    "        best_config_svm = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df_svm = df_svm.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unigram, binary</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigram, binary</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trigram, binary</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unigram, TF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigram, TF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trigram, TF</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unigram, TF-IDF</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigram, TF-IDF</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trigram, TF-IDF</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config  accuracy\n",
       "0  unigram, binary     0.500\n",
       "1   bigram, binary     0.500\n",
       "2  trigram, binary     0.500\n",
       "3      unigram, TF     0.375\n",
       "4       bigram, TF     0.375\n",
       "5      trigram, TF     0.500\n",
       "6  unigram, TF-IDF     0.500\n",
       "7   bigram, TF-IDF     0.500\n",
       "8  trigram, TF-IDF     0.500"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of svm classifier\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best Configuration:', 'unigram, binary', '0.5000', <30x1137 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 6659 stored elements in Compressed Sparse Row format>, <8x1137 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1624 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "print(best_config_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['120', '40', 'accuracy', 'agreement', 'allcopyright', 'availability', 'available', 'byassociated', 'click', 'company', 'completeness', 'disclaim', 'disclaimerneither', 'electronic', 'express', 'fitness', 'fromtotranslatetranslationprogress', 'implied', 'infringment', 'lessyou', 'license', 'limitation', 'loadinganimation', 'merchantability', 'ms', 'neither', 'non', 'particular', 'photographs', 'post', 'press', 'products', 'purpose', 'rather', 'show', 'specifically', 'systemsproquest', 'timeliness', 'times', 'translatetranslation', 'trump', 'turn', 'undo', 'washinton', 'without', 'word'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.0505522 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.0564099 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.07222846, 0.        , ..., 0.        , 0.        ,\n",
       "        0.0752669 ],\n",
       "       ...,\n",
       "       [0.09953687, 0.        , 0.04658299, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.02298697],\n",
       "       [0.03228227, 0.03740242, 0.03021604, ..., 0.        , 0.03897583,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = processed_sentiment_corpus.sentiment\n",
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=more_stop_words)\n",
    "processed_features = vectorizer.fit_transform(processed_sentiment_corpus.text).toarray()\n",
    "processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(processed_features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4]\n",
      " [0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.33      0.50         6\n",
      "     neutral       0.33      1.00      0.50         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.67      0.67      0.50         8\n",
      "weighted avg       0.83      0.50      0.50         8\n",
      "\n",
      "Random Forest Classifier Accuracy Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "predictions = text_classifier.predict(X_test1)\n",
    "print(confusion_matrix(y_test1,predictions))\n",
    "print(classification_report(y_test1,predictions))\n",
    "print(\"Random Forest Classifier Accuracy Score: \" + str(accuracy_score(y_test1, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
