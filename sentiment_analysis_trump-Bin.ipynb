{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modeling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stopwords_english = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.read_csv('/Users/sa/Desktop/NLP_The-2020-Presidential-Race-master/Data/All_Candidates/Donald_Trump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hide highlightingFull TextTranslateUndo Translation FromToTranslateTranslation in progress... \\n\\n[[missing key: loadingAnimation]]The full text may take 40-120 seconds to translate; larger documents may take longer.\\n\\nCancel\\nOverlayEndTurn on search term navigationTurn on search term navigation\\n| Jump to first hit\\nPresident Trump delivered a straightforward message to the millions of football fans watching the Super Bowl on Sunday: \"The best is yet to come,\" he declared in a campaign ad that ran after the game.\\nBut exactly what comes next for Mr. Trump if he wins a second term is still under discussion at the White House, even as the president plans to continue crisscrossing the nation campaigningâ€”now\\nwith a Senate acquittal\\n, rising approval ratings and increased confidence in his re-election prospects.\\nSenior aidesâ€”led by Chris Liddell, the White House\\'s deputy chief of staff for policy coordinationâ€”have been meeting since late last year to chart an agenda for the second term, according to administration officials. The discussions are in their initial stages, the officials said.\\nThe early outlines of the agenda are starting to emerge, but aides said Mr. Trump hasn\\'t yet signed off on the final details of the plan, though he is receiving regular briefings on the discussions. Among the issues under consideration: continuing the administration\\'s efforts to lower prescription drug prices, pushing for a broad infrastructure bill and taking another crack at reforming the country\\'s immigration system, the officials said. White House aides are still holding out hope that some of these things can get accomplished before the end of the first term, but lawmakers and some in the administration are pessimistic about the chances of finding common ground with Democratic lawmakers this year.\\nSenior aides have also begun discussing ways to lower the deficitâ€”which is projected to reach $1 trillion in 2020â€”and cut taxes for the middle class, as well as roll back more Obama-era regulations. The president\\'s coming budget blueprint, set to be released Monday, is expected to shed more light on his policy priorities.\\nSome in the administration have said privately that Mr. Trump should be doing more to sell voters on his second-term agenda. But others countered that developing a detailed term-two agenda is complicated by uncertainty about the balance of power in Congress in 2021; the White House could be much more aggressive in its legislative proposals if Republicans controlled both chambers.\\nDeputy-level aides from key White House offices gathered at Camp David early last month to discuss the major policy themes they hope to focus on for the rest of 2020 and in the first year of a second term, the officials said. Additional meetings are expected in the coming months.\\nMr. Trump hasn\\'t yet publicly articulated a detailed policy vision for a second term during his frequent campaign rallies and speeches, instead pointing to his first-term record and warning that a Democratic president would blow it all up.\\nAt his State of the Union address Tuesday, Mr. Trump made clear that\\nthe economy will be the core theme\\nof his re-election campaign. Ticking through a list of economic statistics, the president took credit for the U.S.\\'s economic boom and suggested it could all go away if he is denied four more years in the White House.\\nHealth care and education were among the other policy issues Mr. Trump discussed during the speech. He called on Congress to pass legislation that would establish a tax credit meant to encourage wealthy individuals and corporations to provide scholarships to help low-income students afford private or religious schools. The bill, sponsored by Sen. Ted Cruz (R., Texas), hasn\\'t moved forward in the Senate and is unlikely to gain traction in the Democratic-controlled House.\\nBut Mr. Trump has spent more time looking back on the past three years than looking ahead to his possible second term.\\nDuring a rally in Des Moines, Iowa, last week, the president vowed to usher in a Republican Congress to enact new immigration policies, negotiate new trade deals, offer an alternative to Obamacare and usher in new breakthroughs in science to cure childhood cancers and end the AIDS epidemic.\\nThe bulk of his remarks focused on what he sees as the threat Democrats pose to the country.\\n\"In short, this election is a choice between American freedom and Democratic socialism, and in some cases, in my opinion, it\\'s worse than socialism,\" he said. \"Socialism is a kind word by comparison.\"\\nSHARE YOUR THOUGHTS\\nWhat policy issues do you think President Trump should focus on if he wins a second term? Join the conversation below.\\nMr. Trump\\'s advisers say drawing a contrast with Democrats is a winning strategy. Some of them believe the president\\'s appeal to his devoted base stems less from his specific policy positions and more from his image as a political outsider who is taking on Washington\\'s elite.\\nAnd some longtime political strategists agree.\\n\"He ran as the disrupter in chief; has governed as the disrupter in chief, and will run for re-election as the disrupter in chief,\" said Chris Lehane, a former adviser to Bill Clinton and Al Gore. \"You could even make an argument that the less he sounds like a typical, conventional politician, including having a typical conventional agenda, the more he\\'s on message.\"\\nThe president\\'s advisers also believe Mr. Trump has a strong record to run on. As a result, much of Mr. Trump\\'s campaign trail rhetoric looks back on his first-term accomplishments, from criminal justice legislation to the trade deals he struck with China, Mexico and Canada, to the strong economy.\\n\"The election will be a stark study in contrasts, between the Democrats who offer massive government intervention into people\\'s lives and President Trump who promotes liberty, economic freedom, and prosperity,\" Trump campaign spokesman Tim Murtaugh said in a statement.\\nVeterans of past administrations and presidential campaigns said Mr. Trump\\'s first-term performance is what many voters care about the most.\\n\"If they\\'re voting for the president, they\\'re likely picking the president for retrospective reasons,\" said Lanhee Chen, who served as the policy director to Mitt Romney\\'s 2012 presidential campaign. \"It\\'s much more important for the challenger to define their agenda, than the incumbent.\"\\nMr. Chen nonetheless suggested Mr. Trump opens himself up to criticism from his opponents for not laying out a detailed agenda for the second term. During the 2012 election, for example, Mr. Romney repeatedly called on Barack Obama to flesh out his agenda, arguing he wasn\\'t saying enough about what he would do if he won four more years in office.\\n\"They have no agenda for the future, no agenda for America, no agenda for a second term,\" Mr. Romney said during an October 2012 rally.\\nSome past presidents have outlined detailed visions for a second term as they campaigned for re-election. Bill Clinton, for example, called for a \"bridge to the 21st century\" in 1996, which included a plan to help welfare recipients get jobs. But other presidents have taken a similar approach to Mr. Trump by emphasizing the economic success of their first term, as Ronald Reagan did in his \"Morning in America\" advertising campaign.\\nCecilia MuÃ±oz, who led the White House Domestic Policy Council for the last five years of the Obama administration, said senior aides were having in-depth conversations about a second term at this point in Mr. Obama\\'s presidency.\\n\"The conversations were robust. We were an administration of planners,\" she said, adding, \"There was a time when you had a president with a clear vision and a team expected to plan for that vision.\"\\nWrite to Andrew Restuccia at\\nAndrew.Restuccia@wsj.com\\n\\nCredit: By Andrew Restuccia Word count: 1221Show lessYou have requested \"on-the-fly\" machine translation of selected content from our databases. This functionality is provided solely for your convenience and is in no way intended to replace human translation. Show full disclaimerNeither ProQuest nor its licensors make any representations or warranties with respect to the translations. The translations are automatically generated \"AS IS\" and \"AS AVAILABLE\" and are not retained in our systems. PROQUEST AND ITS LICENSORS SPECIFICALLY DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES FOR AVAILABILITY, ACCURACY, TIMELINESS, COMPLETENESS, NON-INFRINGMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Your use of the translations is subject to all use restrictions contained in your Electronic Products License Agreement and by using the translation functionality you agree to forgo any and all claims against ProQuest or its licensors for your use of the translation functionality and any output derived there from. Hide full disclaimer\\n\\nLonger documents can take a while to translate. Rather than keep you waiting, we have only translated the first few paragraphs. Click the button below if you want to translate the rest of the document.\\nTranslate AllCopyright 2020 Dow Jones & Company, Inc. All Rights Reserved.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['text'][355]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trump's Second-Term Agenda Still on the Drawing Board; The president rarely discusses what he would do if he wins another term, but his advisers have begun to sketch out ideas\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['title'][355]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand annotation indicies\n",
    "positive = [320, 321, 323, 324, 326, 344, 346, 348, 349, 355]\n",
    "\n",
    "negative = [1, 2, 3, 6, 7, 9, 10, 11, 12, 17, 18, 100, 332]\n",
    "\n",
    "neutral = [0, 4, 5, 8, 13, 14, 15, 16, 19, 300, 310, 325, 328, 341, 352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new col for sentiment\n",
    "\n",
    "trump['sentiment'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate rows in new col with corresponding sentiment\n",
    "\n",
    "for i in trump.index:\n",
    "    for j in positive:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'pos'\n",
    "            \n",
    "for i in trump.index:\n",
    "    for j in neutral:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'neutral'\n",
    "            \n",
    "for i in trump.index:\n",
    "    for j in negative:\n",
    "        if i == j:\n",
    "            trump.at[i,'sentiment'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select text and news company names\n",
    "trump_sentiment = trump[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create corpus for each sentiment\n",
    "\n",
    "def create_corpus(trump_sentiment, sentiment_name):\n",
    "    \n",
    "    df1 = trump_sentiment.loc[trump_sentiment['sentiment'] == sentiment_name]\n",
    "    #df2 = Sanders_news.loc[Sanders_news['media'] == media_name]\n",
    "    #df3 = Trump_news.loc[Trump_news['media'] == media_name]\n",
    "    #frames = [df1, df2, df3]\n",
    "    #df = pd.concat(frames, ignore_index = True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small corpus for each sentiment\n",
    "POS = create_corpus(trump_sentiment, sentiment_name = 'pos')\n",
    "NEG = create_corpus(trump_sentiment, sentiment_name = 'neg')\n",
    "NEUTRAL = create_corpus(trump_sentiment, sentiment_name = 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "1  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "2  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "3  Hide highlightingFull TextTranslateUndo Transl...       pos\n",
       "4  Hide highlightingFull TextTranslateUndo Transl...       pos"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_All_sentiment = pd.concat([POS, NEG, NEUTRAL], axis = 0, ignore_index = True)\n",
    "corpus_All_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Preprocessing(corpus):\n",
    "    # convert string to list i.e. ['hide', 'highlightingfull', '[[missing']\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "\n",
    "    # lower case each item in the list, and remove non-alphabetic characters i.e. ['hide', 'highlightingfull', 'missing']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [re.sub(r'[^a-zA-Z]', \"\",y.lower()) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string and replace keywords containing the target names\n",
    "#     keywords = ['new york times', 'the new york times', 'international new york times'\n",
    "#                 \"the washington post\", \"WP Company LLC\", \"washpostcom\",\n",
    "#                 'wall street journal', 'thomaswsjcom', 'Dow Jones Company Inc.']\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x)])\n",
    "\n",
    "    # stem each word in the text\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "    corpus['text'] = corpus['text'].str.split()\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "\n",
    "    # join the item in the list back to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: [' '.join(x)])\n",
    "\n",
    "    # convert list to a string\n",
    "    corpus['text'] = corpus['text'].apply(lambda x: str(x[0]))\n",
    "\n",
    "    print(type(corpus.iloc[0]['text']))\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide highlightingful texttranslateundo transla...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hide highlightingful texttranslateundo transla...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  hide highlightingful texttranslateundo transla...       pos\n",
       "1  hide highlightingful texttranslateundo transla...       pos"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentiment_corpus = Data_Preprocessing(corpus_All_sentiment)\n",
    "processed_sentiment_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Split training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    hide highlightingful texttranslateundo transla...\n",
       "11    hide highlightingful texttranslateundo transla...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate features and targets\n",
    "X = processed_sentiment_corpus.iloc[:, 0]\n",
    "y = processed_sentiment_corpus.iloc[:, 1]\n",
    "\n",
    "# split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0, 'neutral': 1, 'pos': 2}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "# get label name mapping\n",
    "le.fit(y_train)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "# encode the target \n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Getting document term matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Create matrix of token counts using unigram, bigram and trigram tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram matrix of token counts\n",
    "\n",
    "def get_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range, binary=True) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram token counts matrix\n",
    "binary1_train, binary1_test = get_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram token counts matrix\n",
    "binary2_train, binary2_test = get_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram token counts matrix\n",
    "binary3_train, binary3_test = get_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in binary1_train is: 1134\n",
      "The unique terms in binary2_train is: 1623\n",
      "The unique terms in binary3_train is: 1798\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in binary1_train is:\", binary1_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary2_train is:\", binary2_train.toarray().shape[1])\n",
    "print(\"The unique terms in binary3_train is:\", binary3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Create DTM using unigram, bigram and trigram term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram term frequency matrix\n",
    "\n",
    "def get_TF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tf matrix\n",
    "tf1_train, tf1_test = get_TF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf matrix\n",
    "tf2_train, tf2_test = get_TF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf matrix\n",
    "tf3_train, tf3_test = get_TF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tf1_train is: 1134\n",
      "The unique terms in tf2_train is: 1623\n",
      "The unique terms in tf3_train is: 1798\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tf1_train is:\", tf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf2_train is:\", tf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tf3_train is:\", tf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Create DTM using unigram, bigram and trigram TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unigram, bigram, and trigram TF-IDF matrix\n",
    "\n",
    "def get_TF_IDF_DTM(Ngram_range, x_train, x_test):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df = int(3), max_df = 0.5, \n",
    "                                 ngram_range = Ngram_range) \n",
    "    vectorizer.fit(x_train)\n",
    "    trans_x_train = vectorizer.transform(x_train)\n",
    "    trans_x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    return trans_x_train, trans_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unigram tf-idf matrix\n",
    "tfidf1_train, tfidf1_test = get_TF_IDF_DTM(Ngram_range = (1, 1), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# bigram tf-idf matrix\n",
    "tfidf2_train, tfidf2_test = get_TF_IDF_DTM(Ngram_range = (1, 2), x_train = X_train, x_test = X_test)\n",
    "\n",
    "# trigram tf-idf matrix\n",
    "tfidf3_train, tfidf3_test = get_TF_IDF_DTM(Ngram_range = (1, 3), x_train = X_train, x_test = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique terms in tfidf1_train is: 1134\n",
      "The unique terms in tfidf2_train is: 1623\n",
      "The unique terms in tfidf3_train is: 1798\n"
     ]
    }
   ],
   "source": [
    "print(\"The unique terms in tfidf1_train is:\", tfidf1_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf2_train is:\", tfidf2_train.toarray().shape[1])\n",
    "print(\"The unique terms in tfidf3_train is:\", tfidf3_train.toarray().shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model training\n",
    "def train_model(clf, dtm, test):\n",
    "    # train data\n",
    "    clf.fit(dtm, y_train)\n",
    "    \n",
    "    # Predicting on the test set\n",
    "    preds = clf.predict(test)\n",
    "    \n",
    "    # print evaluation matrix\n",
    "    print(\"Accuracy:\", '{:1.4f}'.format(accuracy_score(y_test, preds)))\n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    return '{:1.4f}'.format(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 0.6250\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.58      0.61      0.59         8\n",
      "weighted avg       0.59      0.62      0.60         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [1 1 1]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.81      0.78      0.72         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [1 1 1]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.81      0.78      0.72         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [1 1 1]\n",
      " [0 0 2]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 0.8750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.83      0.84         8\n",
      "weighted avg       0.91      0.88      0.86         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 3 0]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.72      0.72      0.72         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 2 1]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.72      0.72      0.72         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 2 1]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.8750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.83      0.84         8\n",
      "weighted avg       0.91      0.88      0.86         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 3 0]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.8750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.83      0.84         8\n",
      "weighted avg       0.91      0.88      0.86         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 3 0]\n",
      " [0 1 1]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.7500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.50      0.67      0.57         8\n",
      "weighted avg       0.56      0.75      0.64         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [0 3 0]\n",
      " [1 1 0]]\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Use Naive Bayes\n",
    "#clf = XGBClassifier() #MultinomialNB()\n",
    "#clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "#param = {'max_depth': 3, 'eta': 0.3, 'objective':'multi:softmax', 'num_class': 3}\n",
    "# param = {'max_depth': 3, 'learning_rate ': 0.3, 'objective':'multi:softmax'}\n",
    "#xgb_clf = XGBClassifier(param)\n",
    "#xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.3, objective='multi:softmax')\n",
    "xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.3, objective='multi:softmax', num_class=3)\n",
    "#svm_clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "# reference: https://medium.com/@gabrielziegler3/multiclass-multilabel-classification-with-xgboost-66195e4d9f2d\n",
    "# reference: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "# Model Configurations\n",
    "binary1 = (\"unigram, binary\", binary1_train, binary1_test)\n",
    "binary2 = (\"bigram, binary\",  binary2_train, binary2_test)\n",
    "binary3 = (\"trigram, binary\", binary3_train, binary3_test)\n",
    "tf1 = (\"unigram, TF\", tf1_train, tf1_test)\n",
    "tf2 = (\"bigram, TF\",  tf2_train, tf2_test)\n",
    "tf3 = (\"trigram, TF\", tf3_train, tf3_test)\n",
    "tfidf1 = (\"unigram, TF-IDF\", tfidf1_train, tfidf1_test)\n",
    "tfidf2 = (\"bigram, TF-IDF\",  tfidf2_train, tfidf2_test)\n",
    "tfidf3 = (\"trigram, TF-IDF\", tfidf3_train, tfidf3_test)\n",
    "DTMs = [binary1, binary2, binary3,\n",
    "        tf1, tf2, tf3,\n",
    "        tfidf1, tfidf2, tfidf3]\n",
    "\n",
    "df = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = xgb_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config[2]):\n",
    "        best_config = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df = df.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram, binary\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, binary\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, binary\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "unigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "bigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n",
      "trigram, TF-IDF\n",
      "\n",
      "Accuracy: 0.3750\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.12      0.33      0.18         8\n",
      "weighted avg       0.14      0.38      0.20         8\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 3 0]\n",
      " [0 3 0]\n",
      " [0 2 0]]\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sa/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC(gamma = 'scale', C = 1.0)\n",
    "# svm classifier\n",
    "df_svm = pd.DataFrame({\"config\": [],\n",
    "                   \"accuracy\": []})\n",
    "best_config_svm = [\"Best Configuration\", \"none\", 0, \"none\", \"none\"]\n",
    "for data in DTMs:\n",
    "    print(data[0])\n",
    "    print(\"\")\n",
    "    score = train_model(clf = svm_clf, dtm = data[1], test = data[2])\n",
    "    print(\"======================================================\")\n",
    "    print(\"\")\n",
    "    if float(score) > float(best_config_svm[2]):\n",
    "        best_config_svm = [\"Best Configuration:\", data[0], score, data[1], data[2]]\n",
    "    df_svm = df_svm.append({\"config\": data[0],\n",
    "               \"accuracy\": float(score)},\n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unigram, binary</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigram, binary</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trigram, binary</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unigram, TF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigram, TF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trigram, TF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unigram, TF-IDF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigram, TF-IDF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trigram, TF-IDF</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config  accuracy\n",
       "0  unigram, binary     0.375\n",
       "1   bigram, binary     0.375\n",
       "2  trigram, binary     0.375\n",
       "3      unigram, TF     0.375\n",
       "4       bigram, TF     0.375\n",
       "5      trigram, TF     0.375\n",
       "6  unigram, TF-IDF     0.375\n",
       "7   bigram, TF-IDF     0.375\n",
       "8  trigram, TF-IDF     0.375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of svm classifier\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best Configuration:', 'unigram, binary', '0.3750', <30x1134 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 6802 stored elements in Compressed Sparse Row format>, <8x1134 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1462 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "print(best_config_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
